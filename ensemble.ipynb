{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117194,"databundleVersionId":14005367,"sourceType":"competition"},{"sourceId":13340141,"sourceType":"datasetVersion","datasetId":8459293},{"sourceId":604754,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":453532,"modelId":469825},{"sourceId":604761,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":453538,"modelId":469829}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms, models\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport numpy as np\nfrom PIL import Image\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_classes = 9\nbatch_size = 16\ndata_dir = \"/kaggle/input/AI-OF-GOD-4/aog_data/test/images\"\n\nefficientnet_paths = [\n    \"/kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold1.pth\",\n    \"/kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold2.pth\",\n    \"/kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold3.pth\",\n]\n\nswin_paths = [\n    \"/kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold1_epoch10.pth\",\n    \"/kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold2_epoch9.pth\",\n    \"/kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold3_epoch10.pth\",\n]\n\ntest_transform = transforms.Compose([\n    transforms.Resize((384, 384)),\n    transforms.CenterCrop(384),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nclass TestImageDataset(torch.utils.data.Dataset):\n    def __init__(self, folder, transform):\n        self.paths = sorted([\n            os.path.join(folder, fname)\n            for fname in os.listdir(folder)\n            if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n        ])\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        img_path = self.paths[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, os.path.basename(img_path)\n\ntest_dataset = TestImageDataset(data_dir, test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\ndef load_efficientnet_model(path):\n    model = models.efficientnet_v2_l(weights=None)\n    in_features = model.classifier[1].in_features\n    model.classifier[1] = nn.Linear(in_features, num_classes)\n    state_dict = torch.load(path, map_location=device)\n    model.load_state_dict(state_dict, strict=False)\n    model.to(device)\n    model.eval()\n    return model\n\ndef load_swin_model(path):\n    model = models.swin_v2_s(weights=None)\n    in_features = model.head.in_features\n    model.head = nn.Linear(in_features, num_classes)\n    state_dict = torch.load(path, map_location=device)\n    if any(k.startswith(\"module.\") for k in state_dict.keys()):\n        state_dict = {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n    model.load_state_dict(state_dict, strict=False)\n    model.to(device)\n    model.eval()\n    return model\n\ndef get_ensemble_predictions(model_paths, loader, model_loader_fn):\n    all_probs = []\n    for path in model_paths:\n        print(f\"Loading model from {path}\")\n        model = model_loader_fn(path)\n        probs = []\n        with torch.no_grad():\n            for inputs, _ in tqdm(loader, leave=False):\n                inputs = inputs.to(device)\n                outputs = model(inputs)\n                preds = torch.softmax(outputs, dim=1)\n                probs.append(preds.cpu().numpy())\n        probs = np.concatenate(probs, axis=0)\n        all_probs.append(probs)\n    ensemble_probs = np.mean(all_probs, axis=0)\n    return ensemble_probs\n\nprint(\"\\nðŸ”¹ Generating EfficientNetV2-L ensemble predictions...\")\neffnet_preds = get_ensemble_predictions(efficientnet_paths, test_loader, load_efficientnet_model)\n\nprint(\"\\nðŸ”¹ Generating SwinV2-S ensemble predictions...\")\nswin_preds = get_ensemble_predictions(swin_paths, test_loader, load_swin_model)\n\nfinal_probs = (effnet_preds + swin_preds) / 2\nfinal_labels = np.argmax(final_probs, axis=1)\n\noutput_file = \"ensemble_predictions.csv\"\nwith open(output_file, \"w\") as f:\n    f.write(\"filename,label\\n\")\n    for (_, filename), label in zip(test_dataset, final_labels):\n        f.write(f\"{filename},{label}\\n\")\n\nprint(f\"\\nâœ… Ensemble inference complete! Saved results to: {output_file}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:20:16.721037Z","iopub.execute_input":"2025-10-11T18:20:16.721652Z","iopub.status.idle":"2025-10-11T18:35:37.805656Z","shell.execute_reply.started":"2025-10-11T18:20:16.721624Z","shell.execute_reply":"2025-10-11T18:35:37.804813Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Generating EfficientNetV2-L ensemble predictions...\nLoading model from /kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold1.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold2.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold3.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"\nðŸ”¹ Generating SwinV2-S ensemble predictions...\nLoading model from /kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold1_epoch10.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold2_epoch9.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold3_epoch10.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"\nâœ… Ensemble inference complete! Saved results to: ensemble_predictions.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport ast\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms, models\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_classes = 9\nbatch_size = 16\ndata_dir = \"/kaggle/input/AI-OF-GOD-4/aog_data/test/images\"\nmaxvit_csv = \"/kaggle/input/aiofgod-vitmax-ensemble-preds/maxvit_5fold_probs.csv\"\n\nswin_paths = [\n    \"/kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold1_epoch10.pth\",\n    \"/kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold2_epoch9.pth\",\n    \"/kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold3_epoch10.pth\",\n]\n\ntest_transform = transforms.Compose([\n    transforms.Resize((384, 384)),\n    transforms.CenterCrop(384),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nclass TestImageDataset(torch.utils.data.Dataset):\n    def __init__(self, folder, transform):\n        self.paths = sorted([\n            os.path.join(folder, fname)\n            for fname in os.listdir(folder)\n            if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n        ])\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        img_path = self.paths[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, os.path.basename(img_path)\n\ntest_dataset = TestImageDataset(data_dir, test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\ndef load_swin_model(path):\n    model = models.swin_v2_s(weights=None)\n    in_features = model.head.in_features\n    model.head = nn.Linear(in_features, num_classes)\n    state_dict = torch.load(path, map_location=device)\n    if any(k.startswith(\"module.\") for k in state_dict.keys()):\n        state_dict = {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n    model.load_state_dict(state_dict, strict=False)\n    model.to(device)\n    model.eval()\n    return model\n\ndef get_ensemble_predictions(model_paths, loader, model_loader_fn):\n    all_probs = []\n    for path in model_paths:\n        print(f\"Loading model from {path}\")\n        model = model_loader_fn(path)\n        probs = []\n        with torch.no_grad():\n            for inputs, _ in tqdm(loader, leave=False):\n                inputs = inputs.to(device)\n                outputs = model(inputs)\n                preds = torch.softmax(outputs, dim=1)\n                probs.append(preds.cpu().numpy())\n        probs = np.concatenate(probs, axis=0)\n        all_probs.append(probs)\n    return np.mean(all_probs, axis=0)\n\nprint(\"\\nðŸ”¹ Loading MaxViT 5-fold predictions...\")\ndf = pd.read_csv(maxvit_csv)\nfor col in [c for c in df.columns if \"fold_\" in c]:\n    df[col] = df[col].apply(lambda x: np.array(ast.literal_eval(x), dtype=np.float32))\n\nprob_arrays = np.stack([np.vstack(df[c].to_numpy()) for c in df.columns if \"fold_\" in c], axis=0)\nmaxvit_ensemble_probs = prob_arrays.mean(axis=0)\nprint(f\"âœ… Averaged {prob_arrays.shape[0]} MaxViT folds â†’ shape {maxvit_ensemble_probs.shape}\")\n\nprint(\"\\nðŸ”¹ Generating SwinV2-S ensemble predictions...\")\nswin_preds = get_ensemble_predictions(swin_paths, test_loader, load_swin_model)\n\nfinal_probs = (maxvit_ensemble_probs + swin_preds) / 2\nfinal_labels = np.argmax(final_probs, axis=1)\n\noutput_file = \"final_ensemble_predictions.csv\"\nwith open(output_file, \"w\") as f:\n    f.write(\"filename,label\\n\")\n    for (_, filename), label in zip(test_dataset, final_labels):\n        f.write(f\"{filename},{label}\\n\")\n\nprint(f\"\\nâœ… Final ensemble complete! Saved results to: {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T18:58:24.340109Z","iopub.execute_input":"2025-10-11T18:58:24.340437Z","iopub.status.idle":"2025-10-11T19:05:46.250406Z","shell.execute_reply.started":"2025-10-11T18:58:24.340411Z","shell.execute_reply":"2025-10-11T19:05:46.249269Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Loading MaxViT 5-fold predictions...\nâœ… Averaged 5 MaxViT folds â†’ shape (5253, 9)\n\nðŸ”¹ Generating SwinV2-S ensemble predictions...\nLoading model from /kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold1_epoch10.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold2_epoch9.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold3_epoch10.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"\nâœ… Final ensemble complete! Saved results to: final_ensemble_predictions.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport ast\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms, models\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_classes = 9\nbatch_size = 16\ndata_dir = \"/kaggle/input/AI-OF-GOD-4/aog_data/test/images\"\n\nefficientnet_paths = [\n    \"/kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold1.pth\",\n    \"/kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold2.pth\",\n    \"/kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold3.pth\",\n]\n\nswin_paths = [\n    \"/kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold1_epoch10.pth\",\n    \"/kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold2_epoch9.pth\",\n    \"/kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold3_epoch10.pth\",\n]\n\nmaxvit_csv = \"/kaggle/input/aiofgod-vitmax-ensemble-preds/maxvit_5fold_probs.csv\"\n\ntest_transform = transforms.Compose([\n    transforms.Resize((384, 384)),\n    transforms.CenterCrop(384),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nclass TestImageDataset(torch.utils.data.Dataset):\n    def __init__(self, folder, transform):\n        self.paths = sorted([\n            os.path.join(folder, fname)\n            for fname in os.listdir(folder)\n            if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n        ])\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        img_path = self.paths[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, os.path.basename(img_path)\n\ntest_dataset = TestImageDataset(data_dir, test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\ndef load_efficientnet_model(path):\n    model = models.efficientnet_v2_l(weights=None)\n    in_features = model.classifier[1].in_features\n    model.classifier[1] = nn.Linear(in_features, num_classes)\n    state_dict = torch.load(path, map_location=device)\n    model.load_state_dict(state_dict, strict=False)\n    model.to(device)\n    model.eval()\n    return model\n\ndef load_swin_model(path):\n    model = models.swin_v2_s(weights=None)\n    in_features = model.head.in_features\n    model.head = nn.Linear(in_features, num_classes)\n    state_dict = torch.load(path, map_location=device)\n    if any(k.startswith(\"module.\") for k in state_dict.keys()):\n        state_dict = {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n    model.load_state_dict(state_dict, strict=False)\n    model.to(device)\n    model.eval()\n    return model\n\ndef get_ensemble_predictions(model_paths, loader, model_loader_fn):\n    all_probs = []\n    for path in model_paths:\n        print(f\"Loading model from {path}\")\n        model = model_loader_fn(path)\n        probs = []\n        with torch.no_grad():\n            for inputs, _ in tqdm(loader, leave=False):\n                inputs = inputs.to(device)\n                outputs = model(inputs)\n                probs.append(torch.softmax(outputs, dim=1).cpu().numpy())\n        all_probs.append(np.concatenate(probs, axis=0))\n    return np.mean(all_probs, axis=0)\n\nprint(\"\\nðŸ”¹ Loading MaxViT 5-fold predictions...\")\ndf = pd.read_csv(maxvit_csv)\nfor col in [c for c in df.columns if \"fold_\" in c]:\n    df[col] = df[col].apply(lambda x: np.array(ast.literal_eval(x), dtype=np.float32))\n\nprob_arrays = np.stack([np.vstack(df[c].to_numpy()) for c in df.columns if \"fold_\" in c], axis=0)\nmaxvit_ensemble_probs = prob_arrays.mean(axis=0)\nprint(f\"âœ… MaxViT ensemble shape: {maxvit_ensemble_probs.shape}\")\n\nprint(\"\\nðŸ”¹ Generating EfficientNetV2-L ensemble predictions...\")\neffnet_preds = get_ensemble_predictions(efficientnet_paths, test_loader, load_efficientnet_model)\n\nprint(\"\\nðŸ”¹ Generating SwinV2-S ensemble predictions...\")\nswin_preds = get_ensemble_predictions(swin_paths, test_loader, load_swin_model)\n\nfinal_probs = (maxvit_ensemble_probs + effnet_preds + swin_preds) / 3\nfinal_labels = np.argmax(final_probs, axis=1)\n\noutput_file = \"final_ensemble_predictions.csv\"\nwith open(output_file, \"w\") as f:\n    f.write(\"filename,label\\n\")\n    for (_, filename), label in zip(test_dataset, final_labels):\n        f.write(f\"{filename},{label}\\n\")\n\nprint(f\"\\nâœ… Final ensemble (MaxViT + EfficientNet + Swin) complete! Saved results to: {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:13:58.326993Z","iopub.execute_input":"2025-10-11T19:13:58.327700Z","iopub.status.idle":"2025-10-11T19:29:17.108153Z","shell.execute_reply.started":"2025-10-11T19:13:58.327667Z","shell.execute_reply":"2025-10-11T19:29:17.107119Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Loading MaxViT 5-fold predictions...\nâœ… MaxViT ensemble shape: (5253, 9)\n\nðŸ”¹ Generating EfficientNetV2-L ensemble predictions...\nLoading model from /kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold1.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold2.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/efficientnet-v2_l-ensemble/pytorch/default/1/efficientnetv2l_best_fold3.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"\nðŸ”¹ Generating SwinV2-S ensemble predictions...\nLoading model from /kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold1_epoch10.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold2_epoch9.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Loading model from /kaggle/input/swin-v2_s/pytorch/default/1/best_model_fold3_epoch10.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"\nâœ… Final ensemble (MaxViT + EfficientNet + Swin) complete! Saved results to: final_ensemble_predictions.csv\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}