{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117194,"databundleVersionId":14005367,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ----------------------------\n# Imports\n# ----------------------------\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import transforms, datasets\nfrom torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.isotonic import IsotonicRegression\nfrom scipy.special import softmax\nimport numpy as np\nimport pandas as pd\nimport os\n\n# ----------------------------\n# Device\n# ----------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# ----------------------------\n# Paths & Hyperparameters\n# ----------------------------\ndata_dir = \"/kaggle/input/AI-OF-GOD-4/aog_data/train\"\ntest_data_dir = \"/kaggle/input/AI-OF-GOD-4/aog_data/test\"\nnum_classes = 9\nbatch_size = 32\nlr = 1e-4\nepochs = 5\nk_folds = 5\ntest_split_ratio = 0.05\n\n# ----------------------------\n# Transforms - use official ImageNet stats!\n# ----------------------------\n\nmean = [0.3789, 0.3898, 0.3800]\nstd = [0.2241, 0.2245, 0.2227]\n\ntrain_tfms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\nval_tfms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\n# ----------------------------\n# Load Datasets\n# ----------------------------\nfull_dataset = datasets.ImageFolder(root=data_dir, transform=train_tfms)\ntest_dataset = datasets.ImageFolder(root=test_data_dir, transform=val_tfms)\nnum_samples = len(full_dataset)\n\n# ----------------------------\n# Initial Split for Hold-out Test\n# ----------------------------\ntest_size = int(test_split_ratio * num_samples)\ntrainval_size = num_samples - test_size\n\nindices = np.arange(num_samples)\nnp.random.shuffle(indices)\ntrainval_indices = indices[:trainval_size]\nholdout_test_indices = indices[trainval_size:]\n\ntrainval_dataset = Subset(full_dataset, trainval_indices)\nholdout_test_dataset = Subset(full_dataset, holdout_test_indices)\nholdout_test_dataset.dataset.transform = val_tfms\n\n# For stratified k-fold: get labels for trainval split\ntrainval_labels = [full_dataset.targets[i] for i in trainval_indices]\n\n# ----------------------------\n# Stratified K-Fold CV\n# ----------------------------\nskf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\nfold_best_metrics = []\nfold_best_models = []\nfor fold, (fold_train_idx, fold_val_idx) in enumerate(skf.split(trainval_indices, trainval_labels)):\n    print(f\"\\n========== Fold {fold+1}/{k_folds} ==========\")\n    train_indices = [trainval_indices[i] for i in fold_train_idx]\n    val_indices = [trainval_indices[i] for i in fold_val_idx]\n    train_subset = Subset(full_dataset, train_indices)\n    val_subset = Subset(full_dataset, val_indices)\n    val_subset.dataset.transform = val_tfms\n\n    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n    model = convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n    for param in model.parameters():\n        param.requires_grad = True   # <-- FULL FINE-TUNING\n    in_features = model.classifier[2].in_features\n    model.classifier[2] = nn.Linear(in_features, num_classes)\n    model = model.to(device)\n\n\n    fold_train_labels = [full_dataset.targets[i] for i in train_indices]\n    class_counts = np.bincount(fold_train_labels, minlength=num_classes)\n    class_weights = 1.0 / (np.sqrt(np.maximum(class_counts, 1)))\n    weights_tensor = torch.FloatTensor(class_weights).to(device)\n\n    criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    best_metric = -1\n    best_model_state = None\n    best_filename = None\n\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1} [Train]\"):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        print(f\"Epoch [{epoch+1}] Loss: {running_loss/len(train_loader):.4f}\")\n\n        model.eval()\n        all_labels, all_preds = [], []\n        with torch.no_grad():\n            for images, labels in tqdm(val_loader, desc=f\"Fold {fold+1} Epoch {epoch+1} [Val]\"):\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                all_labels.extend(labels.cpu().numpy())\n                all_preds.extend(predicted.cpu().numpy())\n        all_labels = np.array(all_labels)\n        all_preds = np.array(all_preds)\n\n        cm = confusion_matrix(all_labels, all_preds, labels=range(num_classes))\n        per_class_acc = cm.diagonal() / cm.sum(axis=1)\n        per_class_prec = precision_score(all_labels, all_preds, labels=range(num_classes), average=None, zero_division=0)\n        per_class_rec = recall_score(all_labels, all_preds, labels=range(num_classes), average=None, zero_division=0)\n        overall_acc = np.mean(all_preds == all_labels) * 100\n        overall_prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n        overall_rec = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n\n        print(f\"\\n{'='*15} Fold {fold+1} Epoch {epoch+1} Validation Metrics {'='*15}\")\n        print(f\"{'Class':<8}{'Accuracy':>10}{'Precision':>12}{'Recall':>10}\")\n        print(\"-\" * 40)\n        for i in range(num_classes):\n            acc = per_class_acc[i] if not np.isnan(per_class_acc[i]) else 0.0\n            prec = per_class_prec[i] if not np.isnan(per_class_prec[i]) else 0.0\n            rec = per_class_rec[i] if not np.isnan(per_class_rec[i]) else 0.0\n            print(f\"{i:<8}{acc:>10.4f}{prec:>12.4f}{rec:>10.4f}\")\n        print(\"-\" * 40)\n        print(f\"{'Overall':<8}{overall_acc:>10.2f}{overall_prec*100:>12.2f}{overall_rec*100:>10.2f}\")\n        print(f\"{'='*55}\\n\")\n\n        composite_metric = overall_acc + overall_prec * 100 + overall_rec * 100\n        if composite_metric > best_metric:\n            best_metric = composite_metric\n            best_model_state = model.state_dict()\n            best_filename = f\"bestmodel_fold{fold+1}_epoch{epoch+1}_acc{overall_acc:.2f}_prec{overall_prec:.4f}_rec{overall_rec:.4f}.pt\"\n            torch.save(best_model_state, best_filename)\n            print(f\"Best model for fold {fold+1} updated and saved as {best_filename}\")\n\n    fold_best_metrics.append(best_metric)\n    fold_best_models.append(best_filename)\n\n# ----------------------------\n# Retrain Best Fold Model On Full Trainval\n# ----------------------------\nbest_fold_idx = np.argmax(fold_best_metrics)\nbest_model_path = fold_best_models[best_fold_idx]\nprint(f\"\\nUsing best model from fold {best_fold_idx+1}: {best_model_path}\")\n\nmodel = convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\nfor param in model.parameters():\n    param.requires_grad = True   # <-- FULL FINE-TUNING\nin_features = model.classifier[2].in_features\nmodel.classifier[2] = nn.Linear(in_features, num_classes)\nmodel = model.to(device)\nmodel.load_state_dict(torch.load(best_model_path))\n\ntrain_labels = [full_dataset.targets[i] for i in trainval_indices]\nclass_counts = np.bincount(train_labels, minlength=num_classes)\nclass_weights = 1. / (np.sqrt(np.maximum(class_counts, 1)))\nweights_tensor = torch.FloatTensor(class_weights).to(device)\ncriterion = nn.CrossEntropyLoss(weight=weights_tensor)\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nfull_train_loader = DataLoader(trainval_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    for images, labels in tqdm(full_train_loader, desc=f\"Retrain Epoch {epoch+1}\"):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    print(f\"Epoch [{epoch+1}] Loss: {running_loss/len(full_train_loader):.4f}\")\n\n# ----------------------------\n# CALIBRATION AND TEST EVALUATION\n# ----------------------------\n# --- Collect validation logits/labels for calibration\nval_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\nval_logits, val_labels = [], []\nmodel.eval()\nwith torch.no_grad():\n    for images, labels in tqdm(val_loader, desc=\"Collecting validation logits\"):\n        images = images.to(device)\n        outputs = model(images)\n        val_logits.append(outputs.cpu().numpy())\n        val_labels.append(labels.cpu().numpy())\nval_logits = np.concatenate(val_logits)\nval_labels = np.concatenate(val_labels)\nval_probs = softmax(val_logits, axis=1)\n\n# --- Fit isotonic regression per class\ncalibrators = []\nfor i in range(num_classes):\n    y_bin = (val_labels == i).astype(int)\n    calibrator = IsotonicRegression(out_of_bounds=\"clip\")\n    calibrator.fit(val_probs[:, i], y_bin)\n    calibrators.append(calibrator)\n\n# --- Gather logits for hold-out test set\nholdout_test_loader = DataLoader(holdout_test_dataset, batch_size=1, shuffle=False, num_workers=2)\ntest_logits, test_labels = [], []\nwith torch.no_grad():\n    for images, labels in tqdm(holdout_test_loader, desc=\"Holdout test logits\"):\n        images = images.to(device)\n        outputs = model(images)\n        test_logits.append(outputs.cpu().numpy())\n        test_labels.append(labels.cpu().numpy())\ntest_logits = np.concatenate(test_logits)\ntest_labels = np.concatenate(test_labels)\ntest_probs = softmax(test_logits, axis=1)\n\n# --- Calibrate hold-out test probabilities\ncal_test_probs = np.zeros_like(test_probs)\nfor i in range(num_classes):\n    cal_test_probs[:, i] = calibrators[i].transform(test_probs[:, i])\ncal_test_preds = np.argmax(cal_test_probs, axis=1)\n\n# --- Print calibrated test metrics\ncm = confusion_matrix(test_labels, cal_test_preds, labels=range(num_classes))\nper_class_acc = cm.diagonal() / cm.sum(axis=1)\nper_class_prec = precision_score(test_labels, cal_test_preds, labels=range(num_classes), average=None, zero_division=0)\nper_class_rec = recall_score(test_labels, cal_test_preds, labels=range(num_classes), average=None, zero_division=0)\noverall_acc = accuracy_score(test_labels, cal_test_preds) * 100\noverall_prec = precision_score(test_labels, cal_test_preds, average='macro', zero_division=0)\noverall_rec = recall_score(test_labels, cal_test_preds, average='macro', zero_division=0)\n\nprint(f\"\\n{'='*15} Hold-out Test Metrics (Calibrated) {'='*15}\")\nprint(f\"{'Class':<8}{'Accuracy':>10}{'Precision':>12}{'Recall':>10}\")\nprint(\"-\" * 40)\nfor i in range(num_classes):\n    acc = per_class_acc[i] if not np.isnan(per_class_acc[i]) else 0.0\n    prec = per_class_prec[i] if not np.isnan(per_class_prec[i]) else 0.0\n    rec = per_class_rec[i] if not np.isnan(per_class_rec[i]) else 0.0\n    print(f\"{i:<8}{acc:>10.4f}{prec:>12.4f}{rec:>10.4f}\")\nprint(\"-\" * 40)\nprint(f\"{'Overall':<8}{overall_acc:>10.2f}{overall_prec*100:>12.2f}{overall_rec*100:>10.2f}\")\nprint(f\"{'='*55}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T02:56:32.147755Z","iopub.execute_input":"2025-10-11T02:56:32.148163Z","iopub.status.idle":"2025-10-11T04:32:29.120178Z","shell.execute_reply.started":"2025-10-11T02:56:32.148140Z","shell.execute_reply":"2025-10-11T04:32:29.119010Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n\n========== Fold 1/5 ==========\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n100%|██████████| 109M/109M [00:01<00:00, 78.6MB/s] \nFold 1 Epoch 1 [Train]: 100%|██████████| 292/292 [02:40<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1] Loss: 0.6371\n","output_type":"stream"},{"name":"stderr","text":"Fold 1 Epoch 1 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 1 Epoch 1 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.6887      0.9369    0.6887\n1           0.8741      0.9843    0.8741\n2           0.9373      0.9660    0.9373\n3           1.0000      0.9172    1.0000\n4           0.9924      0.9091    0.9924\n5           0.9790      0.8917    0.9790\n6           0.9699      0.9214    0.9699\n7           0.9728      0.8034    0.9728\n8           0.9044      0.8092    0.9044\n----------------------------------------\nOverall      92.87       90.44     92.43\n=======================================================\n\nBest model for fold 1 updated and saved as bestmodel_fold1_epoch1_acc92.87_prec0.9044_rec0.9243.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 1 Epoch 2 [Train]: 100%|██████████| 292/292 [02:52<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2] Loss: 0.1614\n","output_type":"stream"},{"name":"stderr","text":"Fold 1 Epoch 2 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 1 Epoch 2 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.8278      0.9328    0.8278\n1           0.9720      0.8742    0.9720\n2           0.9530      0.9593    0.9530\n3           0.9323      0.9841    0.9323\n4           1.0000      0.8733    1.0000\n5           0.9580      0.9013    0.9580\n6           0.9474      0.9921    0.9474\n7           0.8844      0.8966    0.8844\n8           0.8971      0.9242    0.8971\n----------------------------------------\nOverall      93.99       92.64     93.02\n=======================================================\n\nBest model for fold 1 updated and saved as bestmodel_fold1_epoch2_acc93.99_prec0.9264_rec0.9302.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 1 Epoch 3 [Train]: 100%|██████████| 292/292 [02:54<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3] Loss: 0.0545\n","output_type":"stream"},{"name":"stderr","text":"Fold 1 Epoch 3 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 1 Epoch 3 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.7483      0.9741    0.7483\n1           0.9720      0.9205    0.9720\n2           0.9323      0.9809    0.9323\n3           0.9850      0.9850    0.9850\n4           1.0000      0.7486    1.0000\n5           0.9510      0.9714    0.9510\n6           0.9774      0.9848    0.9774\n7           0.9592      0.9338    0.9592\n8           0.9412      0.7151    0.9412\n----------------------------------------\nOverall      93.56       91.27     94.07\n=======================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Fold 1 Epoch 4 [Train]: 100%|██████████| 292/292 [02:51<00:00,  1.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4] Loss: 0.0412\n","output_type":"stream"},{"name":"stderr","text":"Fold 1 Epoch 4 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 1 Epoch 4 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.8146      0.9462    0.8146\n1           0.9510      0.9067    0.9510\n2           0.9538      0.9706    0.9538\n3           1.0000      0.9433    1.0000\n4           1.0000      0.9357    1.0000\n5           0.9301      0.9110    0.9301\n6           0.9850      0.9493    0.9850\n7           0.9252      0.9510    0.9252\n8           0.9191      0.8333    0.9191\n----------------------------------------\nOverall      94.63       92.74     94.21\n=======================================================\n\nBest model for fold 1 updated and saved as bestmodel_fold1_epoch4_acc94.63_prec0.9274_rec0.9421.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 1 Epoch 5 [Train]: 100%|██████████| 292/292 [02:54<00:00,  1.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5] Loss: 0.0332\n","output_type":"stream"},{"name":"stderr","text":"Fold 1 Epoch 5 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 1 Epoch 5 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.6887      0.9811    0.6887\n1           0.9371      0.9178    0.9371\n2           0.9612      0.9620    0.9612\n3           0.9624      0.9922    0.9624\n4           0.9466      0.9538    0.9466\n5           0.9510      0.9252    0.9510\n6           0.9925      0.9103    0.9925\n7           0.9796      0.8675    0.9796\n8           0.8676      0.7919    0.8676\n----------------------------------------\nOverall      93.82       92.24     92.08\n=======================================================\n\n\n========== Fold 2/5 ==========\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 1 [Train]: 100%|██████████| 292/292 [02:54<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1] Loss: 0.6423\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 1 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 2 Epoch 1 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.8808      0.7644    0.8808\n1           0.8951      0.9481    0.8951\n2           0.9349      0.9742    0.9349\n3           0.8872      0.9916    0.8872\n4           0.9154      0.9520    0.9154\n5           0.9650      0.7931    0.9650\n6           0.9774      0.9220    0.9774\n7           0.9796      0.8623    0.9796\n8           0.8456      0.8846    0.8456\n----------------------------------------\nOverall      92.70       89.91     92.01\n=======================================================\n\nBest model for fold 2 updated and saved as bestmodel_fold2_epoch1_acc92.70_prec0.8991_rec0.9201.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 2 [Train]: 100%|██████████| 292/292 [02:51<00:00,  1.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2] Loss: 0.1655\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 2 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 2 Epoch 2 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.9470      0.7688    0.9470\n1           0.8881      0.9922    0.8881\n2           0.9365      0.9776    0.9365\n3           0.9474      0.9767    0.9474\n4           0.9538      0.9764    0.9538\n5           0.9161      0.9161    0.9161\n6           0.9925      0.8250    0.9925\n7           0.9932      0.9241    0.9932\n8           0.8897      0.8897    0.8897\n----------------------------------------\nOverall      93.86       91.63     94.05\n=======================================================\n\nBest model for fold 2 updated and saved as bestmodel_fold2_epoch2_acc93.86_prec0.9163_rec0.9405.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 3 [Train]: 100%|██████████| 292/292 [02:53<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3] Loss: 0.0599\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 3 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 2 Epoch 3 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.8146      0.9179    0.8146\n1           0.8951      0.9624    0.8951\n2           0.9827      0.9342    0.9827\n3           0.9774      0.9559    0.9774\n4           0.9538      0.9688    0.9538\n5           0.9371      0.9504    0.9371\n6           0.9474      0.9844    0.9474\n7           0.9660      0.9281    0.9660\n8           0.7279      0.9900    0.7279\n----------------------------------------\nOverall      94.38       95.47     91.13\n=======================================================\n\nBest model for fold 2 updated and saved as bestmodel_fold2_epoch3_acc94.38_prec0.9547_rec0.9113.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 4 [Train]: 100%|██████████| 292/292 [02:52<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4] Loss: 0.0443\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 4 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 2 Epoch 4 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.9205      0.8528    0.9205\n1           0.9091      0.9701    0.9091\n2           0.9258      0.9851    0.9258\n3           0.9925      0.9429    0.9925\n4           0.9923      0.7371    0.9923\n5           0.9441      0.9122    0.9441\n6           0.9624      0.9552    0.9624\n7           0.9932      0.9125    0.9932\n8           0.8750      0.8815    0.8750\n----------------------------------------\nOverall      93.65       90.55     94.61\n=======================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 5 [Train]: 100%|██████████| 292/292 [02:54<00:00,  1.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5] Loss: 0.0376\n","output_type":"stream"},{"name":"stderr","text":"Fold 2 Epoch 5 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 2 Epoch 5 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.8212      0.9254    0.8212\n1           0.9301      0.9500    0.9301\n2           0.9819      0.9430    0.9819\n3           0.9850      0.9776    0.9850\n4           0.9154      0.9754    0.9154\n5           0.9510      0.9128    0.9510\n6           0.9474      1.0000    0.9474\n7           0.9456      0.9456    0.9456\n8           0.8015      0.9561    0.8015\n----------------------------------------\nOverall      94.80       95.40     91.99\n=======================================================\n\nBest model for fold 2 updated and saved as bestmodel_fold2_epoch5_acc94.80_prec0.9540_rec0.9199.pt\n\n========== Fold 3/5 ==========\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 1 [Train]: 100%|██████████| 292/292 [02:53<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1] Loss: 0.6400\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 1 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 3 Epoch 1 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.7533      0.8760    0.7533\n1           0.9792      0.7382    0.9792\n2           0.8038      0.9909    0.8038\n3           1.0000      0.7037    1.0000\n4           0.9846      0.6845    0.9846\n5           0.8741      0.8446    0.8741\n6           0.9697      0.8366    0.9697\n7           0.9932      0.7737    0.9932\n8           0.8971      0.7722    0.8971\n----------------------------------------\nOverall      86.39       80.23     91.72\n=======================================================\n\nBest model for fold 3 updated and saved as bestmodel_fold3_epoch1_acc86.39_prec0.8023_rec0.9172.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 2 [Train]: 100%|██████████| 292/292 [02:52<00:00,  1.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2] Loss: 0.1660\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 2 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 3 Epoch 2 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.9067      0.8662    0.9067\n1           0.8333      0.9917    0.8333\n2           0.9736      0.9395    0.9736\n3           0.9549      0.9769    0.9549\n4           0.9462      0.9609    0.9462\n5           0.9441      0.9000    0.9441\n6           0.9848      0.9220    0.9848\n7           0.8581      0.9845    0.8581\n8           0.8235      0.9655    0.8235\n----------------------------------------\nOverall      94.07       94.53     91.39\n=======================================================\n\nBest model for fold 3 updated and saved as bestmodel_fold3_epoch2_acc94.07_prec0.9453_rec0.9139.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 3 [Train]: 100%|██████████| 292/292 [02:53<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3] Loss: 0.0582\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 3 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 3 Epoch 3 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.7867      0.9516    0.7867\n1           0.9861      0.7396    0.9861\n2           0.9489      0.9812    0.9489\n3           0.9925      0.9778    0.9925\n4           0.9692      0.9692    0.9692\n5           0.9371      0.9371    0.9371\n6           0.9848      0.9559    0.9848\n7           0.9730      0.9231    0.9730\n8           0.8676      0.8429    0.8676\n----------------------------------------\nOverall      94.25       91.98     93.84\n=======================================================\n\nBest model for fold 3 updated and saved as bestmodel_fold3_epoch3_acc94.25_prec0.9198_rec0.9384.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 4 [Train]: 100%|██████████| 292/292 [02:51<00:00,  1.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4] Loss: 0.0332\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 4 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 3 Epoch 4 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.6200      0.9894    0.6200\n1           0.8889      0.8889    0.8889\n2           0.9621      0.9358    0.9621\n3           0.9925      0.9565    0.9925\n4           0.9615      0.8013    0.9615\n5           0.8531      0.9173    0.8531\n6           0.9394      0.9538    0.9394\n7           0.9730      0.8471    0.9730\n8           0.7647      0.8889    0.7647\n----------------------------------------\nOverall      91.84       90.88     88.39\n=======================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 5 [Train]: 100%|██████████| 292/292 [02:54<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5] Loss: 0.0356\n","output_type":"stream"},{"name":"stderr","text":"Fold 3 Epoch 5 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 3 Epoch 5 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.8533      0.9078    0.8533\n1           0.9722      0.9032    0.9722\n2           0.9555      0.9772    0.9555\n3           0.9850      0.9704    0.9850\n4           0.9462      0.9840    0.9462\n5           0.9510      0.9067    0.9510\n6           0.9848      0.9701    0.9848\n7           0.9865      0.9241    0.9865\n8           0.9118      0.8552    0.9118\n----------------------------------------\nOverall      95.19       93.32     94.96\n=======================================================\n\nBest model for fold 3 updated and saved as bestmodel_fold3_epoch5_acc95.19_prec0.9332_rec0.9496.pt\n\n========== Fold 4/5 ==========\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 1 [Train]: 100%|██████████| 292/292 [02:53<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1] Loss: 0.6604\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 1 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 4 Epoch 1 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.8267      0.8052    0.8267\n1           0.9861      0.6368    0.9861\n2           0.8384      0.9760    0.8384\n3           0.9925      0.7097    0.9925\n4           0.9846      0.7033    0.9846\n5           0.6875      0.9519    0.6875\n6           0.9318      0.9389    0.9318\n7           0.9932      0.7766    0.9932\n8           0.7794      0.8908    0.7794\n----------------------------------------\nOverall      86.60       82.10     89.11\n=======================================================\n\nBest model for fold 4 updated and saved as bestmodel_fold4_epoch1_acc86.60_prec0.8210_rec0.8911.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 2 [Train]: 100%|██████████| 292/292 [02:53<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2] Loss: 0.1596\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 2 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 4 Epoch 2 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.7000      0.9459    0.7000\n1           0.9583      0.9200    0.9583\n2           0.9744      0.9494    0.9744\n3           0.9925      0.9565    0.9925\n4           0.9769      0.8944    0.9769\n5           0.8750      0.9065    0.8750\n6           0.9394      0.9841    0.9394\n7           0.9864      0.9603    0.9864\n8           0.8162      0.8740    0.8162\n----------------------------------------\nOverall      94.03       93.23     91.32\n=======================================================\n\nBest model for fold 4 updated and saved as bestmodel_fold4_epoch2_acc94.03_prec0.9323_rec0.9132.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 3 [Train]: 100%|██████████| 292/292 [02:54<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3] Loss: 0.0643\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 3 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 4 Epoch 3 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.9133      0.7527    0.9133\n1           0.8958      0.9773    0.8958\n2           0.9431      0.9720    0.9431\n3           0.9850      0.9357    0.9850\n4           0.9385      0.9683    0.9385\n5           0.8542      0.9389    0.8542\n6           0.9697      0.9014    0.9697\n7           0.9796      0.9290    0.9796\n8           0.9118      0.8611    0.9118\n----------------------------------------\nOverall      93.69       91.52     93.23\n=======================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 4 [Train]: 100%|██████████| 292/292 [02:52<00:00,  1.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4] Loss: 0.0308\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 4 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 4 Epoch 4 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.8533      0.8767    0.8533\n1           0.9375      0.9507    0.9375\n2           0.9662      0.9750    0.9662\n3           1.0000      0.9638    1.0000\n4           0.9308      0.9918    0.9308\n5           0.9306      0.9116    0.9306\n6           0.9773      0.9627    0.9773\n7           0.9932      0.9481    0.9932\n8           0.9265      0.8750    0.9265\n----------------------------------------\nOverall      95.49       93.95     94.61\n=======================================================\n\nBest model for fold 4 updated and saved as bestmodel_fold4_epoch4_acc95.49_prec0.9395_rec0.9461.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 5 [Train]: 100%|██████████| 292/292 [02:53<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5] Loss: 0.0266\n","output_type":"stream"},{"name":"stderr","text":"Fold 4 Epoch 5 [Val]: 100%|██████████| 73/73 [00:11<00:00,  6.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 4 Epoch 5 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.8333      0.8803    0.8333\n1           0.9514      0.9580    0.9514\n2           0.9662      0.9513    0.9662\n3           0.9549      0.9922    0.9549\n4           0.7769      1.0000    0.7769\n5           0.9375      0.9247    0.9375\n6           0.9167      0.9918    0.9167\n7           0.9864      0.9295    0.9864\n8           0.9044      0.7736    0.9044\n----------------------------------------\nOverall      93.86       93.35     91.42\n=======================================================\n\n\n========== Fold 5/5 ==========\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 1 [Train]: 100%|██████████| 292/292 [02:54<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1] Loss: 0.5958\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 1 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 5 Epoch 1 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.7020      0.9138    0.7020\n1           0.9790      0.6635    0.9790\n2           0.9167      0.9841    0.9167\n3           0.9699      0.9416    0.9699\n4           0.9308      0.8121    0.9308\n5           0.9371      0.8645    0.9371\n6           0.9015      0.9917    0.9015\n7           0.9388      0.9718    0.9388\n8           0.9265      0.7500    0.9265\n----------------------------------------\nOverall      91.28       87.70     91.14\n=======================================================\n\nBest model for fold 5 updated and saved as bestmodel_fold5_epoch1_acc91.28_prec0.8770_rec0.9114.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 2 [Train]: 100%|██████████| 292/292 [02:55<00:00,  1.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2] Loss: 0.1547\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 2 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 5 Epoch 2 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.9272      0.8434    0.9272\n1           0.9650      0.7005    0.9650\n2           0.9497      0.9746    0.9497\n3           0.9774      0.9420    0.9774\n4           0.9231      0.9524    0.9231\n5           0.9021      0.9556    0.9021\n6           0.9470      0.9542    0.9470\n7           0.9320      0.9514    0.9320\n8           0.7574      0.9450    0.7574\n----------------------------------------\nOverall      93.38       91.32     92.01\n=======================================================\n\nBest model for fold 5 updated and saved as bestmodel_fold5_epoch2_acc93.38_prec0.9132_rec0.9201.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 3 [Train]: 100%|██████████| 292/292 [02:52<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3] Loss: 0.0548\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 3 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 5 Epoch 3 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.9603      0.7632    0.9603\n1           0.9231      0.9851    0.9231\n2           0.9382      0.9777    0.9382\n3           0.9925      0.9362    0.9925\n4           0.8000      0.9811    0.8000\n5           0.9860      0.8011    0.9860\n6           0.9470      0.8446    0.9470\n7           0.9252      1.0000    0.9252\n8           0.8676      0.8872    0.8676\n----------------------------------------\nOverall      93.26       90.85     92.66\n=======================================================\n\nBest model for fold 5 updated and saved as bestmodel_fold5_epoch3_acc93.26_prec0.9085_rec0.9266.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 4 [Train]: 100%|██████████| 292/292 [02:53<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4] Loss: 0.0297\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 4 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 5 Epoch 4 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.9603      0.7923    0.9603\n1           0.8951      0.9922    0.8951\n2           0.9580      0.9773    0.9580\n3           0.9925      0.9362    0.9925\n4           0.9308      0.9237    0.9308\n5           0.9720      0.9026    0.9720\n6           0.9470      0.8929    0.9470\n7           0.9592      0.9792    0.9592\n8           0.8235      0.9573    0.8235\n----------------------------------------\nOverall      94.72       92.82     93.76\n=======================================================\n\nBest model for fold 5 updated and saved as bestmodel_fold5_epoch4_acc94.72_prec0.9282_rec0.9376.pt\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 5 [Train]: 100%|██████████| 292/292 [02:54<00:00,  1.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5] Loss: 0.0449\n","output_type":"stream"},{"name":"stderr","text":"Fold 5 Epoch 5 [Val]: 100%|██████████| 73/73 [00:12<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n=============== Fold 5 Epoch 5 Validation Metrics ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.9205      0.8688    0.9205\n1           0.9161      0.9493    0.9161\n2           0.9670      0.9568    0.9670\n3           0.9699      0.9773    0.9699\n4           0.8846      0.9746    0.8846\n5           0.9790      0.8750    0.9790\n6           0.9318      0.9248    0.9318\n7           0.9796      0.9351    0.9796\n8           0.7721      0.9813    0.7721\n----------------------------------------\nOverall      94.46       93.81     92.45\n=======================================================\n\n\nUsing best model from fold 4: bestmodel_fold4_epoch4_acc95.49_prec0.9395_rec0.9461.pt\n","output_type":"stream"},{"name":"stderr","text":"Retrain Epoch 1: 100%|██████████| 364/364 [03:36<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1] Loss: 0.0884\n","output_type":"stream"},{"name":"stderr","text":"Retrain Epoch 2: 100%|██████████| 364/364 [03:36<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2] Loss: 0.0313\n","output_type":"stream"},{"name":"stderr","text":"Retrain Epoch 3: 100%|██████████| 364/364 [03:35<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3] Loss: 0.0359\n","output_type":"stream"},{"name":"stderr","text":"Retrain Epoch 4: 100%|██████████| 364/364 [03:35<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4] Loss: 0.0368\n","output_type":"stream"},{"name":"stderr","text":"Retrain Epoch 5: 100%|██████████| 364/364 [03:35<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5] Loss: 0.0192\n","output_type":"stream"},{"name":"stderr","text":"Collecting validation logits: 100%|██████████| 73/73 [00:12<00:00,  6.07it/s]\nHoldout test logits: 100%|██████████| 612/612 [00:05<00:00, 112.57it/s]","output_type":"stream"},{"name":"stdout","text":"\n=============== Hold-out Test Metrics (Calibrated) ===============\nClass     Accuracy   Precision    Recall\n----------------------------------------\n0           0.9143      0.9143    0.9143\n1           0.9737      0.9487    0.9737\n2           0.9808      0.9503    0.9808\n3           0.8750      0.9545    0.8750\n4           0.9655      0.9655    0.9655\n5           0.8919      0.9706    0.8919\n6           0.9667      1.0000    0.9667\n7           0.8974      0.9459    0.8974\n8           0.9545      0.9767    0.9545\n----------------------------------------\nOverall      95.42       95.85     93.55\n=======================================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport numpy as np\nfrom scipy.special import softmax\n\n# Set model to evaluation mode\nmodel.eval()\n\ntest_dataset = datasets.ImageFolder(root=test_data_dir, transform=val_tfms)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n\nsubmission_rows = []\nwith torch.no_grad():\n    for batch_idx, (images, _) in enumerate(tqdm(test_loader, desc=\"Generating Submission\")):\n        batch_start = batch_idx * test_loader.batch_size\n        filenames = [\n            test_dataset.imgs[batch_start + i][0].split('/')[-1]\n            for i in range(len(images))\n        ]\n        images = images.to(device)\n        outputs = model(images)                       # [batch, num_classes]\n        logits = outputs.cpu().numpy()                # [batch, num_classes]\n        probs = softmax(logits, axis=1)               # [batch, num_classes]\n\n        # Calibrate probabilities using fitted calibrators\n        calibrated_probs = np.zeros_like(probs)\n        for i in range(num_classes):\n            calibrated_probs[:, i] = calibrators[i].transform(probs[:, i])\n        pred_labels = np.argmax(calibrated_probs, axis=1)\n\n        for fname, label in zip(filenames, pred_labels):\n            submission_rows.append({'filename': fname, 'label': label})\n\nsubmission_df = pd.DataFrame(submission_rows)\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Saved sample submission to submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T04:32:29.122061Z","iopub.execute_input":"2025-10-11T04:32:29.122637Z","iopub.status.idle":"2025-10-11T04:33:00.205370Z","shell.execute_reply.started":"2025-10-11T04:32:29.122612Z","shell.execute_reply":"2025-10-11T04:33:00.204403Z"}},"outputs":[{"name":"stderr","text":"Generating Submission: 100%|██████████| 165/165 [00:27<00:00,  6.10it/s]","output_type":"stream"},{"name":"stdout","text":"Saved sample submission to submission.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}