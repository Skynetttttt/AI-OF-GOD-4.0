{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms, models\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport numpy as np\nimport copy\n\ndata_dir = \"/kaggle/input/AI-OF-GOD-4/aog_data/train\"\nnum_classes = 9\nbatch_size = 16\nnum_epochs = 10\nnum_folds = 5\nlr = 1e-4\nstart_fold = 1\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"âœ… Using device: {device}\")\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nfull_dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\ntargets = [label for _, label in full_dataset.imgs]\ntargets = np.array(targets)\n\nskf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(targets)), targets)):\n    if fold < start_fold:\n        print(f\"\\nâœ… Skipping Fold {fold + 1} (already trained)\\n\")\n        continue\n\n    print(f\"\\n======================== Fold {fold + 1}/{num_folds} ========================\\n\")\n\n    train_subset = Subset(full_dataset, train_idx)\n    val_subset = Subset(copy.deepcopy(full_dataset), val_idx)\n    val_subset.dataset.transform = val_transform\n\n    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n    model = models.maxvit_t(weights=models.MaxVit_T_Weights.IMAGENET1K_V1)\n    model.classifier[5] = nn.Linear(model.classifier[5].in_features, num_classes)\n    model = model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=lr)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print(\"-\" * 40)\n\n        model.train()\n        train_loss, train_preds, train_labels = 0.0, [], []\n        for imgs, labels in tqdm(train_loader, desc=\"Training\"):\n            imgs, labels = imgs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * imgs.size(0)\n            train_preds.extend(outputs.argmax(1).cpu().numpy())\n            train_labels.extend(labels.cpu().numpy())\n\n        train_acc = accuracy_score(train_labels, train_preds)\n        train_loss /= len(train_subset)\n\n        model.eval()\n        val_loss, val_preds, val_labels = 0.0, [], []\n        with torch.no_grad():\n            for imgs, labels in tqdm(val_loader, desc=\"Validation\"):\n                imgs, labels = imgs.to(device), labels.to(device)\n                outputs = model(imgs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item() * imgs.size(0)\n                val_preds.extend(outputs.argmax(1).cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n\n        val_acc = accuracy_score(val_labels, val_preds)\n        val_loss /= len(val_subset)\n        scheduler.step()\n\n        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n        print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n\n        if val_acc > best_acc:\n            best_acc = val_acc\n            save_path = f\"best_maxvit_fold_{fold+1}.pth\"\n            torch.save(model.state_dict(), save_path)\n            print(f\"âœ… Saved Best Model for Fold {fold+1} at {save_path}\")\n\n    print(f\"\\nâœ… Fold {fold+1} Best Val Accuracy: {best_acc:.4f}\\n\")\n\nprint(\"ðŸ”¥ Training completed successfully on single GPU!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T10:10:32.751784Z","iopub.execute_input":"2025-10-11T10:10:32.752063Z"}},"outputs":[{"name":"stdout","text":"âœ… Using device: cuda\n\nâœ… Skipping Fold 1 (already trained)\n\n\n======================== Fold 2/5 ========================\n\nEpoch 1/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:10<00:00,  2.45it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6116 | Train Acc: 0.8048\nVal Loss:   0.2676 | Val Acc:   0.9147\nâœ… Saved Best Model for Fold 2 at best_maxvit_fold_2.pth\nEpoch 2/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:08<00:00,  2.47it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2313 | Train Acc: 0.9280\nVal Loss:   0.2813 | Val Acc:   0.9041\nEpoch 3/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:10<00:00,  2.45it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1425 | Train Acc: 0.9528\nVal Loss:   0.1449 | Val Acc:   0.9551\nâœ… Saved Best Model for Fold 2 at best_maxvit_fold_2.pth\nEpoch 4/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:09<00:00,  2.46it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1044 | Train Acc: 0.9669\nVal Loss:   0.1463 | Val Acc:   0.9555\nâœ… Saved Best Model for Fold 2 at best_maxvit_fold_2.pth\nEpoch 5/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:09<00:00,  2.46it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0651 | Train Acc: 0.9787\nVal Loss:   0.1220 | Val Acc:   0.9633\nâœ… Saved Best Model for Fold 2 at best_maxvit_fold_2.pth\nEpoch 6/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:08<00:00,  2.47it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0528 | Train Acc: 0.9837\nVal Loss:   0.1389 | Val Acc:   0.9596\nEpoch 7/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:09<00:00,  2.46it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0349 | Train Acc: 0.9879\nVal Loss:   0.1141 | Val Acc:   0.9686\nâœ… Saved Best Model for Fold 2 at best_maxvit_fold_2.pth\nEpoch 8/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:10<00:00,  2.45it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0229 | Train Acc: 0.9938\nVal Loss:   0.1018 | Val Acc:   0.9718\nâœ… Saved Best Model for Fold 2 at best_maxvit_fold_2.pth\nEpoch 9/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:10<00:00,  2.45it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0185 | Train Acc: 0.9950\nVal Loss:   0.0953 | Val Acc:   0.9739\nâœ… Saved Best Model for Fold 2 at best_maxvit_fold_2.pth\nEpoch 10/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:09<00:00,  2.46it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0149 | Train Acc: 0.9952\nVal Loss:   0.0939 | Val Acc:   0.9743\nâœ… Saved Best Model for Fold 2 at best_maxvit_fold_2.pth\n\nâœ… Fold 2 Best Val Accuracy: 0.9743\n\n\n======================== Fold 3/5 ========================\n\nEpoch 1/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:09<00:00,  2.46it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6344 | Train Acc: 0.7980\nVal Loss:   0.3184 | Val Acc:   0.8960\nâœ… Saved Best Model for Fold 3 at best_maxvit_fold_3.pth\nEpoch 2/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [04:09<00:00,  2.46it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:20<00:00,  7.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2365 | Train Acc: 0.9229\nVal Loss:   0.2013 | Val Acc:   0.9347\nâœ… Saved Best Model for Fold 3 at best_maxvit_fold_3.pth\nEpoch 3/10\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 270/613 [01:49<02:19,  2.46it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(\"ello\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Hello\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Hiiii\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"HELLO!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Hello!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Hello!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}